{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Approach I am using here is:\n",
    "  1. As the data is distributed in 7 files which are in .parquet format, I first created a bucket in google cloud storage and created a table concating all the files.\n",
    "  2. The data table is very big in size (25.2gb) hence when I trying to  capture it in a dataframe using BigQuery, the system was having a tough time load it.Hence I used sampled data.\n",
    "  3. As the dataset is very imbanced (i.e only 364 records out of 6.7 million were labelled as 1), I created a dataframe which comprised of all records labelled as 1 (i.e 364) and 1000 records labelled as 0.\n",
    "  4. I have used min max scalling as there were few columns which had very big values and that would have effected the model and would have created biasness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe of rows with label as '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  f1  f2  f3  f4   f5   f6   f7  f8  f9  ...   f493  f494  f495  f496  \\\n",
       "0      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "1      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "2      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "3      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "4      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "\n",
       "   f497  f498  f499  f500  f501  f502  \n",
       "0     0     0     0     0     1     0  \n",
       "1     0     1     0     0     0     0  \n",
       "2     1     0     0     0     0     0  \n",
       "3     0     1     0     0     0     0  \n",
       "4     0     1     0     0     0     0  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "* FROM Lucid_0305.table1 where label=1 limit 10000\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df = bq.Query(query).execute().result().to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error,f1_score, confusion_matrix, precision_score, recall_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "plt.style.use('seaborn') #set same style for all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>364.0</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>3.640000e+02</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.950549</td>\n",
       "      <td>3.225865e+06</td>\n",
       "      <td>0.074176</td>\n",
       "      <td>6.013736</td>\n",
       "      <td>0.501145</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>3900.063564</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.052198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.206044</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.630429</td>\n",
       "      <td>7.615695e+06</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>8.739406</td>\n",
       "      <td>0.728284</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>7886.965607</td>\n",
       "      <td>3.994426</td>\n",
       "      <td>0.234775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495553</td>\n",
       "      <td>0.248508</td>\n",
       "      <td>0.436739</td>\n",
       "      <td>0.405019</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.074023</td>\n",
       "      <td>0.178796</td>\n",
       "      <td>0.052414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.048580e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.523576e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>4810.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>8.388327e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>48313.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label          f1            f2          f3          f4          f5  \\\n",
       "count  364.0  364.000000  3.640000e+02  364.000000  364.000000  364.000000   \n",
       "mean     1.0    3.950549  3.225865e+06    0.074176    6.013736    0.501145   \n",
       "std      0.0    7.630429  7.615695e+06    0.577344    8.739406    0.728284   \n",
       "min      1.0    0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "25%      1.0    0.000000  0.000000e+00    0.000000    1.000000    0.083333   \n",
       "50%      1.0    2.000000  7.048580e+05    0.000000    3.000000    0.250000   \n",
       "75%      1.0    4.250000  3.523576e+06    0.000000    7.000000    0.583333   \n",
       "max      1.0   69.000000  8.388327e+07   10.000000   52.000000    4.333333   \n",
       "\n",
       "               f6            f7          f8          f9     ...       f493  \\\n",
       "count  364.000000    364.000000  364.000000  364.000000     ...      364.0   \n",
       "mean     0.071592   3900.063564    0.978022    0.052198     ...        0.0   \n",
       "std      0.104041   7886.965607    3.994426    0.234775     ...        0.0   \n",
       "min      0.000000      0.000000    0.000000    0.000000     ...        0.0   \n",
       "25%      0.011905      0.000000    0.000000    0.000000     ...        0.0   \n",
       "50%      0.035714      0.000000    0.000000    0.000000     ...        0.0   \n",
       "75%      0.083333   4810.000000    0.000000    0.000000     ...        0.0   \n",
       "max      0.619048  48313.000000   39.000000    2.000000     ...        0.0   \n",
       "\n",
       "        f494        f495        f496        f497        f498        f499  \\\n",
       "count  364.0  364.000000  364.000000  364.000000  364.000000  364.000000   \n",
       "mean     0.0    0.428571    0.065934    0.255495    0.206044    0.002747   \n",
       "std      0.0    0.495553    0.248508    0.436739    0.405019    0.052414   \n",
       "min      0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.0    1.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "max      0.0    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             f500        f501        f502  \n",
       "count  364.000000  364.000000  364.000000  \n",
       "mean     0.005495    0.032967    0.002747  \n",
       "std      0.074023    0.178796    0.052414  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 503 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe of rows with label as '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6965.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  f1  f2  f3  f4   f5   f6      f7  f8  f9  ...   f493  f494  f495  \\\n",
       "0      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "1      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "2      0   0   0   0   0  0.0  0.0  6965.0   6   0  ...      0     0     0   \n",
       "3      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "4      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "\n",
       "   f496  f497  f498  f499  f500  f501  f502  \n",
       "0     0     0     1     0     0     0     0  \n",
       "1     0     1     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0     0  \n",
       "3     0     1     0     0     0     0     0  \n",
       "4     0     0     0     0     0     1     0  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1=\"\"\"\n",
    "SELECT\n",
    "* FROM Lucid_0305.table1 where label=0 limit 1000\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df1 = bq.Query(query1).execute().result().to_dataframe()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concating the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1.364000e+03</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.266862</td>\n",
       "      <td>1.318182</td>\n",
       "      <td>1.000528e+06</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>2.052053</td>\n",
       "      <td>0.171004</td>\n",
       "      <td>0.024429</td>\n",
       "      <td>1657.612271</td>\n",
       "      <td>0.530059</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116569</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.230938</td>\n",
       "      <td>0.293255</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.157625</td>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.442482</td>\n",
       "      <td>5.068417</td>\n",
       "      <td>4.307993e+06</td>\n",
       "      <td>0.302088</td>\n",
       "      <td>5.871284</td>\n",
       "      <td>0.489274</td>\n",
       "      <td>0.069896</td>\n",
       "      <td>5451.689753</td>\n",
       "      <td>3.034138</td>\n",
       "      <td>0.139546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321024</td>\n",
       "      <td>0.139345</td>\n",
       "      <td>0.379667</td>\n",
       "      <td>0.421588</td>\n",
       "      <td>0.455421</td>\n",
       "      <td>0.076387</td>\n",
       "      <td>0.364522</td>\n",
       "      <td>0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>8.388327e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>48313.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label           f1            f2           f3           f4  \\\n",
       "count  1364.000000  1364.000000  1.364000e+03  1364.000000  1364.000000   \n",
       "mean      0.266862     1.318182  1.000528e+06     0.021261     2.052053   \n",
       "std       0.442482     5.068417  4.307993e+06     0.302088     5.871284   \n",
       "min       0.000000     0.000000  0.000000e+00     0.000000     0.000000   \n",
       "25%       0.000000     0.000000  0.000000e+00     0.000000     0.000000   \n",
       "50%       0.000000     0.000000  0.000000e+00     0.000000     0.000000   \n",
       "75%       1.000000     0.000000  0.000000e+00     0.000000     1.000000   \n",
       "max       1.000000    89.000000  8.388327e+07    10.000000    53.000000   \n",
       "\n",
       "                f5           f6            f7           f8           f9  \\\n",
       "count  1364.000000  1364.000000   1364.000000  1364.000000  1364.000000   \n",
       "mean      0.171004     0.024429   1657.612271     0.530059     0.018328   \n",
       "std       0.489274     0.069896   5451.689753     3.034138     0.139546   \n",
       "min       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "75%       0.083333     0.011905      0.000000     0.000000     0.000000   \n",
       "max       4.416667     0.630952  48313.000000    39.000000     2.000000   \n",
       "\n",
       "          ...         f493    f494         f495         f496         f497  \\\n",
       "count     ...       1364.0  1364.0  1364.000000  1364.000000  1364.000000   \n",
       "mean      ...          0.0     0.0     0.116569     0.019795     0.174487   \n",
       "std       ...          0.0     0.0     0.321024     0.139345     0.379667   \n",
       "min       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "max       ...          0.0     0.0     1.000000     1.000000     1.000000   \n",
       "\n",
       "              f498         f499         f500         f501         f502  \n",
       "count  1364.000000  1364.000000  1364.000000  1364.000000  1364.000000  \n",
       "mean      0.230938     0.293255     0.005865     0.157625     0.001466  \n",
       "std       0.421588     0.455421     0.076387     0.364522     0.038278  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 503 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames=[df,df1]\n",
    "data=pd.concat(frames)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1     364\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (954, 502), shape of test (410, 502)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.iloc[:,1:]\n",
    "Y = data.loc[:,'label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "#Splitting train and test datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print('Shape of train {}, shape of test {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Min Max Scaling to scale the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking results of 2 scalars\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#MinMax\n",
    "MinMax = MinMaxScaler(feature_range= (0,1))\n",
    "X_train = MinMax.fit_transform(X_train)\n",
    "X_test = MinMax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2']}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lreg_clf = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty':['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(lreg_clf , param_grid, cv = 5 , return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475890985324947"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=None, columns=['model','train_Rsquare','test_Rsquare','train_MSE','test_MSE','f1_score_train','f1_score_test','train_r2_score','test_r2_score','train_precision_score','test_precision_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_r2_score</th>\n",
       "      <th>test_r2_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.041929</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.785913</td>\n",
       "      <td>0.687586</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_Rsquare  test_Rsquare  train_MSE  test_MSE  \\\n",
       "0  Logistic Regression       0.958071      0.939024   0.041929  0.060976   \n",
       "\n",
       "   f1_score_train  f1_score_test  train_r2_score  test_r2_score  \\\n",
       "0        0.915966       0.876847        0.785913       0.687586   \n",
       "\n",
       "   train_precision_score  test_precision_score  \n",
       "0               0.986425              0.946809  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_clf = LogisticRegression(penalty = 'l2')\n",
    "lreg_clf.fit(X_train,y_train)\n",
    "y_lreg_clf = lreg_clf.predict(X_test)\n",
    "train_Rsquare = lreg_clf.score(X_train, y_train)\n",
    "test_Rsquare = lreg_clf.score(X_test, y_test)\n",
    "train_MSE = mean_squared_error(y_train, lreg_clf.predict(X_train))\n",
    "test_MSE = mean_squared_error(y_test, lreg_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, lreg_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, lreg_clf.predict(X_test))\n",
    "train_r2_score=r2_score(y_train,lreg_clf.predict(X_train))\n",
    "test_r2_score=r2_score(y_test,lreg_clf.predict(X_test))\n",
    "train_precision_score=precision_score(y_train,lreg_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,lreg_clf.predict(X_test))\n",
    "results = results.append(pd.Series({'model':'Logistic Regression','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE,\n",
    "                                    'f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_r2_score':train_r2_score,'test_r2_score':test_r2_score,\n",
    "                                    'train_precision_score':train_precision_score,'test_precision_score':test_precision_score}),ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8549019607843137"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train,lreg_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165137614678899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,lreg_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253050576453757"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, lreg_clf.predict(X_train),pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I just wanted to see different metrics that we can consider to evaluate the model. However as it is a classification problem, the best metric would be f1_score and Precision and Recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the exact problem was known it would have been much easier to consider either of the 2 best metric. As f1 score takes the average of the precision and recall which can be pretty bad in some situations hence we will take the harmonic mean i.e. f_beta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta_score=precision_recall_fscore_support(y_train,lreg_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(index=None, columns=['model','f1_score_train','f1_score_test','train_precision_score','test_precision_score','f_beta_score_train','f_beta_score_test','train_recall_score','test_recall_score'])\n",
    "train_recall_score=recall_score(y_train,lreg_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,lreg_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,lreg_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,lreg_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Logistic Regression','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 4, 5, 6, 7, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[3,4, 5,6, 7,8]}\n",
    "grid_search = GridSearchCV(knn_clf , param_grid, cv = 5 , return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962264150943396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "y_knn_clf = knn_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,knn_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,knn_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, knn_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, knn_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,knn_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,knn_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,knn_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,knn_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'KNN Classifier','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter': [1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter':[1000,10000] }\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=0,kernel='linear'), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'max_iter': 1000}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.940251572327044"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_clf = SVC(C=0.5, max_iter=1000,kernel='linear',random_state=0)\n",
    "lsvc_clf.fit(X_train,y_train)\n",
    "y_lsvc_clf = lsvc_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,lsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,lsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, lsvc_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, lsvc_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,lsvc_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,lsvc_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,lsvc_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,lsvc_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Linear','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [5, 6, 7, 8, 10, 12, 15, 20, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=10)\n",
    "param_grid = {'max_depth': [5,6,7, 8,10,12,15, 20, 50, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv = 5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580712788259959"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "3        Decision Tree        0.980080       0.898551               0.995951   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "3              0.948980            0.989464           0.947879   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  \n",
       "3            0.964706           0.853211  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth = 8)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "y_dt_clf = dt_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,dt_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,dt_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, dt_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, dt_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,dt_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,dt_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,dt_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,dt_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f365bfc17d0>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f36573aaa90>, 'bootstrap': [True, False], 'max_depth': [3, 5, 6, 8], 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f36573aac10>},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#Tuning ridge on new dataset\n",
    "param_grid = {\"max_depth\": [3, 5, 6,8],\n",
    "              \"max_features\": sp_randint(1, 40),\n",
    "              \"min_samples_split\": sp_randint(2, 30),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"bootstrap\": [True, False]}\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
    "                                   n_iter=20, random_state=0,n_jobs=-1, return_train_score=True)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 6,\n",
       " 'max_features': 32,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929769392033543"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "3        Decision Tree        0.980080       0.898551               0.995951   \n",
       "4        Random Forest        0.898785       0.829493               0.928870   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "3              0.948980            0.989464           0.947879   \n",
       "4              0.833333            0.947037           0.909623   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  \n",
       "3            0.964706           0.853211  \n",
       "4            0.870588           0.825688  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(bootstrap=True,max_depth=6,max_features=32,min_samples_leaf=2,min_samples_split=3)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "y_rf_clf = rf_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,rf_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rf_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, rf_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, rf_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,rf_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,rf_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,rf_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,rf_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Random Forest','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. SVC-Kernalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter': [1000, 10000], 'gamma': [0.001, 0.01, 0.1, 0.5, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter':[1000,10000], 'gamma':[0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=0,kernel='rbf'), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1, 'max_iter': 1000}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9412997903563941"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "3        Decision Tree        0.980080       0.898551               0.995951   \n",
       "4        Random Forest        0.898785       0.829493               0.928870   \n",
       "5       SCV-Kernalized        0.965517       0.904762               1.000000   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "3              0.948980            0.989464           0.947879   \n",
       "4              0.833333            0.947037           0.909623   \n",
       "5              0.940594            0.981980           0.950610   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  \n",
       "3            0.964706           0.853211  \n",
       "4            0.870588           0.825688  \n",
       "5            0.933333           0.871560  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbfsvc_clf = SVC(C=10,gamma=0.1, max_iter=1000,kernel='rbf',random_state=0,probability=True)\n",
    "rbfsvc_clf.fit(X_train,y_train)\n",
    "y_rbfsvc_clf = rbfsvc_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, rbfsvc_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, rbfsvc_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,rbfsvc_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,rbfsvc_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Kernalized','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'Train and Test f1_score')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3656c44dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['model','f_beta_score_train','f_beta_score_test']\n",
    "results[cols].set_index('model').plot(kind = 'bar', figsize=(15,8));\n",
    "plt.title('Train and Test f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like Decision Tree and SCV kernalized models have performed the best among all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.98\n",
      "Test score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "hard_voting_clf = VotingClassifier(estimators=[('rbfsvc',rbfsvc_clf),('dt',dt_clf)], voting = 'hard')\n",
    "hard_voting_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(hard_voting_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(hard_voting_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Support Vector Classifier-Kernalized with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.982180</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.948055</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.862385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  f1_score_train  f1_score_test  \\\n",
       "0     Logistic Regression        0.915966       0.876847   \n",
       "1          KNN Classifier        0.877944       0.755556   \n",
       "2              SCV-Linear        0.905660       0.891089   \n",
       "3           Decision Tree        0.980080       0.898551   \n",
       "4           Random Forest        0.898785       0.829493   \n",
       "5          SCV-Kernalized        0.965517       0.904762   \n",
       "6  SCV-Kernalized-Bagging        0.982180       0.948780   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.948980            0.989464   \n",
       "4               0.928870              0.833333            0.947037   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.981980   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.947879            0.964706           0.853211  \n",
       "4           0.909623            0.870588           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.948055            0.933333           0.862385  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(rbfsvc_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "train_precision_score=precision_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Kernalized-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.982180</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.948055</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.862385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  f1_score_train  f1_score_test  \\\n",
       "0     Logistic Regression        0.915966       0.876847   \n",
       "1          KNN Classifier        0.877944       0.755556   \n",
       "2              SCV-Linear        0.905660       0.891089   \n",
       "3           Decision Tree        0.980080       0.898551   \n",
       "4           Random Forest        0.898785       0.829493   \n",
       "5          SCV-Kernalized        0.965517       0.904762   \n",
       "6  SCV-Kernalized-Bagging        0.982180       0.948780   \n",
       "7   Logistic-with-Bagging        0.958071       0.939024   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.948980            0.989464   \n",
       "4               0.928870              0.833333            0.947037   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.981980   \n",
       "7               1.000000              0.940594            0.957072   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.947879            0.964706           0.853211  \n",
       "4           0.909623            0.870588           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.948055            0.933333           0.862385  \n",
       "7           0.937513            0.854902           0.816514  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(lreg_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "train_precision_score=precision_score(y_train,bagging_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,bagging_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Logistic-with-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.982180</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.948055</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.862385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.960616</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  f1_score_train  f1_score_test  \\\n",
       "0         Logistic Regression        0.915966       0.876847   \n",
       "1              KNN Classifier        0.877944       0.755556   \n",
       "2                  SCV-Linear        0.905660       0.891089   \n",
       "3               Decision Tree        0.980080       0.898551   \n",
       "4               Random Forest        0.898785       0.829493   \n",
       "5              SCV-Kernalized        0.965517       0.904762   \n",
       "6      SCV-Kernalized-Bagging        0.982180       0.948780   \n",
       "7       Logistic-with-Bagging        0.958071       0.939024   \n",
       "8  Decision Tree-with-Bagging        0.989518       0.960976   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.948980            0.989464   \n",
       "4               0.928870              0.833333            0.947037   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.981980   \n",
       "7               1.000000              0.940594            0.957072   \n",
       "8               0.995951              0.951456            0.989464   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.947879            0.964706           0.853211  \n",
       "4           0.909623            0.870588           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.948055            0.933333           0.862385  \n",
       "7           0.937513            0.854902           0.816514  \n",
       "8           0.960616            0.964706           0.899083  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(dt_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "train_precision_score=precision_score(y_train,bagging_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,bagging_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree-with-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. AdaBoost Classifier for Support Vector Classifier-Kernalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>test f1 micro</th>\n",
       "      <th>train f1 micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.982180</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.948055</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.960616</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adaboost Classifier with Logistic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.966457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model  f1_score_train  f1_score_test  \\\n",
       "0                 Logistic Regression        0.915966       0.876847   \n",
       "1                      KNN Classifier        0.877944       0.755556   \n",
       "2                          SCV-Linear        0.905660       0.891089   \n",
       "3                       Decision Tree        0.980080       0.898551   \n",
       "4                       Random Forest        0.898785       0.829493   \n",
       "5                      SCV-Kernalized        0.965517       0.904762   \n",
       "6              SCV-Kernalized-Bagging        0.982180       0.948780   \n",
       "7               Logistic-with-Bagging        0.958071       0.939024   \n",
       "8          Decision Tree-with-Bagging        0.989518       0.960976   \n",
       "9   Adaboost Classifier with Logistic             NaN            NaN   \n",
       "10            SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "\n",
       "    train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                0.986425              0.946809            0.957072   \n",
       "1                0.966981              0.957746            0.938392   \n",
       "2                0.972973              0.967742            0.951742   \n",
       "3                0.995951              0.948980            0.989464   \n",
       "4                0.928870              0.833333            0.947037   \n",
       "5                1.000000              0.940594            0.981980   \n",
       "6                1.000000              0.940594            0.981980   \n",
       "7                1.000000              0.940594            0.957072   \n",
       "8                0.995951              0.951456            0.989464   \n",
       "9                     NaN                   NaN                 NaN   \n",
       "10               0.974468              0.950000            0.966009   \n",
       "\n",
       "    f_beta_score_test  train_recall_score  test_recall_score  test f1 micro  \\\n",
       "0            0.937513            0.854902           0.816514            NaN   \n",
       "1            0.884541            0.803922           0.623853            NaN   \n",
       "2            0.944911            0.847059           0.825688            NaN   \n",
       "3            0.947879            0.964706           0.853211            NaN   \n",
       "4            0.909623            0.870588           0.825688            NaN   \n",
       "5            0.950610            0.933333           0.871560            NaN   \n",
       "6            0.948055            0.933333           0.862385            NaN   \n",
       "7            0.937513            0.854902           0.816514            NaN   \n",
       "8            0.960616            0.964706           0.899083            NaN   \n",
       "9                 NaN                 NaN                NaN       0.953659   \n",
       "10           0.953002            0.898039           0.871560            NaN   \n",
       "\n",
       "    train f1 micro  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "5              NaN  \n",
       "6              NaN  \n",
       "7              NaN  \n",
       "8              NaN  \n",
       "9         0.966457  \n",
       "10             NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_clf = GridSearchCV(AdaBoostClassifier(base_estimator = rbfsvc_clf,random_state = 0), param_grid, cv=5,return_train_score=True)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "train_precision_score=precision_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,adaboost_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, adaboost_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, adaboost_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,adaboost_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,adaboost_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,adaboost_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Kernalized-Boosting','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.982180</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.948055</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.862385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.960616</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree-AdaBoosting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  f1_score_train  f1_score_test  \\\n",
       "0          Logistic Regression        0.915966       0.876847   \n",
       "1               KNN Classifier        0.877944       0.755556   \n",
       "2                   SCV-Linear        0.905660       0.891089   \n",
       "3                Decision Tree        0.980080       0.898551   \n",
       "4                Random Forest        0.898785       0.829493   \n",
       "5               SCV-Kernalized        0.965517       0.904762   \n",
       "6       SCV-Kernalized-Bagging        0.982180       0.948780   \n",
       "7        Logistic-with-Bagging        0.958071       0.939024   \n",
       "8   Decision Tree-with-Bagging        0.989518       0.960976   \n",
       "9      SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "10   Decision Tree-AdaBoosting        1.000000       0.956098   \n",
       "\n",
       "    train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                0.986425              0.946809            0.957072   \n",
       "1                0.966981              0.957746            0.938392   \n",
       "2                0.972973              0.967742            0.951742   \n",
       "3                0.995951              0.948980            0.989464   \n",
       "4                0.928870              0.833333            0.947037   \n",
       "5                1.000000              0.940594            0.981980   \n",
       "6                1.000000              0.940594            0.981980   \n",
       "7                1.000000              0.940594            0.957072   \n",
       "8                0.995951              0.951456            0.989464   \n",
       "9                0.974468              0.950000            0.966009   \n",
       "10               1.000000              0.933333            1.000000   \n",
       "\n",
       "    f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0            0.937513            0.854902           0.816514  \n",
       "1            0.884541            0.803922           0.623853  \n",
       "2            0.944911            0.847059           0.825688  \n",
       "3            0.947879            0.964706           0.853211  \n",
       "4            0.909623            0.870588           0.825688  \n",
       "5            0.950610            0.933333           0.871560  \n",
       "6            0.948055            0.933333           0.862385  \n",
       "7            0.937513            0.854902           0.816514  \n",
       "8            0.960616            0.964706           0.899083  \n",
       "9            0.953002            0.898039           0.871560  \n",
       "10           0.955832            1.000000           0.899083  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_clf = GridSearchCV(AdaBoostClassifier(base_estimator = dt_clf,random_state = 0), param_grid, cv=5,return_train_score=True)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "train_precision_score=precision_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,adaboost_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, adaboost_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, adaboost_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,adaboost_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,adaboost_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,adaboost_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree-AdaBoosting','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for GradientBoost {'max_features': 'auto', 'learning_rate': 0.1, 'max_depth': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.947879</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.829493</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.909623</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.982180</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.948055</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.862385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.989518</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.960616</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree-AdaBoosting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  f1_score_train  f1_score_test  \\\n",
       "0            Logistic Regression        0.915966       0.876847   \n",
       "1                 KNN Classifier        0.877944       0.755556   \n",
       "2                     SCV-Linear        0.905660       0.891089   \n",
       "3                  Decision Tree        0.980080       0.898551   \n",
       "4                  Random Forest        0.898785       0.829493   \n",
       "5                 SCV-Kernalized        0.965517       0.904762   \n",
       "6         SCV-Kernalized-Bagging        0.982180       0.948780   \n",
       "7          Logistic-with-Bagging        0.958071       0.939024   \n",
       "8     Decision Tree-with-Bagging        0.989518       0.960976   \n",
       "9        SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "10     Decision Tree-AdaBoosting        1.000000       0.956098   \n",
       "11  Gradient Boosting Classifier        1.000000       0.958537   \n",
       "\n",
       "    train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                0.986425              0.946809            0.957072   \n",
       "1                0.966981              0.957746            0.938392   \n",
       "2                0.972973              0.967742            0.951742   \n",
       "3                0.995951              0.948980            0.989464   \n",
       "4                0.928870              0.833333            0.947037   \n",
       "5                1.000000              0.940594            0.981980   \n",
       "6                1.000000              0.940594            0.981980   \n",
       "7                1.000000              0.940594            0.957072   \n",
       "8                0.995951              0.951456            0.989464   \n",
       "9                0.974468              0.950000            0.966009   \n",
       "10               1.000000              0.933333            1.000000   \n",
       "11               1.000000              0.933962            1.000000   \n",
       "\n",
       "    f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0            0.937513            0.854902           0.816514  \n",
       "1            0.884541            0.803922           0.623853  \n",
       "2            0.944911            0.847059           0.825688  \n",
       "3            0.947879            0.964706           0.853211  \n",
       "4            0.909623            0.870588           0.825688  \n",
       "5            0.950610            0.933333           0.871560  \n",
       "6            0.948055            0.933333           0.862385  \n",
       "7            0.937513            0.854902           0.816514  \n",
       "8            0.960616            0.964706           0.899083  \n",
       "9            0.953002            0.898039           0.871560  \n",
       "10           0.955832            1.000000           0.899083  \n",
       "11           0.958350            1.000000           0.908257  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=10, n_estimators= 500)\n",
    "\n",
    "param_grid = {'max_features':['auto', 'log2'], 'learning_rate' : [0.01,0.1], 'max_depth':[5,10,15,30,50]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best parameters for {} {}'.format('GradientBoost', grid_search.best_params_))\n",
    "\n",
    "train_precision_score=precision_score(y_train,grid_search.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,grid_search.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, grid_search.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, grid_search.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,grid_search.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,grid_search.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,grid_search.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,grid_search.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Gradient Boosting Classifier','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'Train and Test f1_score')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3665f7fa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['model','f_beta_score_train','f_beta_score_test']\n",
    "results[cols].set_index('model').plot(kind = 'bar', figsize=(15,8));\n",
    "plt.title('Train and Test f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets work on bigger dataset and predict using the models we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  f1  f2  f3  f4   f5   f6   f7  f8  f9  ...   f493  f494  f495  f496  \\\n",
       "0      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "1      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "2      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "3      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "4      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "\n",
       "   f497  f498  f499  f500  f501  f502  \n",
       "0     0     0     0     0     1     0  \n",
       "1     0     0     0     0     1     0  \n",
       "2     0     0     0     0     1     0  \n",
       "3     0     0     0     0     1     0  \n",
       "4     0     0     0     0     1     0  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1=\"\"\"\n",
    "SELECT\n",
    "* FROM Lucid_0305.table1 where label=0 limit 500000\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df2 = bq.Query(query1).execute().result().to_dataframe()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1=\"\"\"\n",
    "SELECT * FROM Lucid_0305.table1 WHERE label IN \n",
    "    (SELECT label FROM (SELECT label FROM Lucid_0305.table1 ORDER BY RAND() LIMIT 100000) t);\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df3 = bq.Query(query1).execute().result().to_dataframe()\n",
    "df3.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
