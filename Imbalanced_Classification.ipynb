{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attached dataset has already been cleaned because the features are\n",
    "anonymised and it would be difficult for you to clean the dataset without\n",
    "understanding the features. Describe the types of things you would have looked\n",
    "at when cleaning the dataset if you knew what the features meant and how they\n",
    "related to each other, i.e. discuss the kinds of considerations you would make\n",
    "before cleaning a new dataset. What would you look for and how would you\n",
    "handle it?\n",
    "\n",
    "The approach towards cleaning the data:\n",
    "  1. Data Validity/Quality: \n",
    "      i. Check if important columns (Based on business knowledge) are available completly with no major missing values.\n",
    "      ii. Check for the Null values in all the columns.\n",
    "      iii. It is advisable to delete the columns with more then 60-70% of missing data. But sometimes it might happen that an important variable is having more than 60% of missing data. \n",
    "            In that case we can use different imputation techniques which I will mention below\n",
    "      iv. Check if the column is having correct data. Suppose for example a column is for total time spend on website in minutes, and it consists of negative values or value mentioned in hrs. I would have handled this kind of data first.\n",
    "  2. Handling missing values:\n",
    "      First I will identify if the missing is:\n",
    "        a) Missing Completely at random (MCAR): In essence, if we split the data into two more sets. Data missing and Data present. Then check whether the distribution of the variables in each of these sets is the same\n",
    "        b) Missing at random (MAR): \n",
    "        c) Missing not at random (RNAR) or Not missing at random (NMAR):\n",
    "      In the first two cases, it is safe to remove the missing data depending upon their occurrences (delete if >60% missing values). While in the third case removing observations with missing values can produce a bias in the model\n",
    "      Methods:\n",
    "        i. Dropping Variables: When the variable has more than 60% of missing data then it is always better to drop the variable, if the variable is insignificant. Otherwise imputation (which we will discuss later in the article) \n",
    "          is always a better option then dropping the variable.\n",
    "              Data.drop(‘column_name’,axis=1, inplace=True)\n",
    "        ii.Unconditional Imputation: (Mean, Median, Mode)\n",
    "            Mean, Median: when the missing data is around 10%-20% in a particular colummn and I really want to start working on the modeling part then I would use mean/median imputation because it is fast and the most basic type of imputation. \n",
    "                  One major disadvantage is that mean imputation reduces variance in the dataset\n",
    "            Mode: I will use mode imputation for categorical variables in the dataset. \n",
    "        The major limitation of using this methods is that it leads to biased estimates of the variances and covariance. The standard errors and test statistics can also be underestimated and overestimated respectively. \n",
    "        This imputation technique works well with when the values are missing completely at random\n",
    "        iii. Predictive Models: I feel this is the best type of imputation. I mostly use predictive model imputation when time is not the constraint. I would have divided our data set into two sets: One set with no missing values for the variable \n",
    "            (training) and another one with missing values (test) and then use methods like logistic regression and ANOVA for prediction\n",
    "        ** I have a complete github repository dedicated towards handling missing values. The link to that is here https://github.com/siddharthoza/100_days_of_ML_Day_3 **\n",
    "  3. Encoding:\n",
    "      After the imputation is performed I would have then performed encoding. There are basically 3 types of encoding I use.\n",
    "        i. Label Encoding: Suppose a categorical variables have 3 types of values then replace those with numberical values of 1,2,3\n",
    "        ii. Binary Encoding: Suppose a categorical variable is having 2 types of values then replace those with 0,1 (e.g. categorical variables having values such as yes, no or male, female etc.)\n",
    "        iii. One hot encoding: It is a standard approach which is used widely. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Approach:\n",
    "  1. As the data is distributed in 7 files which are in .parquet format, I first created a bucket in google cloud storage and created a table concating all the files.\n",
    "  \n",
    "  2. The data table is very big in size (25.2gb) hence when I trying to  capture it in a dataframe using BigQuery, the system was having a tough time load it.Hence I used sampled data.\n",
    "  3. As the dataset is very imbanced (i.e only 364 records out of 6.7 million were labelled as 1), I created a dataframe which comprised of all records labelled as 1 (i.e 364) and 1000 records labelled as 0.\n",
    "  4. I will be fitting my models on a smaller dataset and then will use those to predict values in larger dataset and calculate f1_score\n",
    "  4. I have used min max scalling as there were few columns which have very large values and that would have effected the model and would have created biasness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe of rows with label as '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  f1  f2  f3  f4   f5   f6   f7  f8  f9  ...   f493  f494  f495  f496  \\\n",
       "0      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "1      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "2      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "3      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "4      1   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "\n",
       "   f497  f498  f499  f500  f501  f502  \n",
       "0     0     0     0     0     1     0  \n",
       "1     0     1     0     0     0     0  \n",
       "2     1     0     0     0     0     0  \n",
       "3     0     1     0     0     0     0  \n",
       "4     0     1     0     0     0     0  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "* FROM Lucid_0305.table1 where label=1 limit 10000\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df = bq.Query(query).execute().result().to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error,f1_score, confusion_matrix, precision_score, recall_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "plt.style.use('seaborn') #set same style for all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>364.0</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>3.640000e+02</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.950549</td>\n",
       "      <td>3.225865e+06</td>\n",
       "      <td>0.074176</td>\n",
       "      <td>6.013736</td>\n",
       "      <td>0.501145</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>3900.063564</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.052198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.255495</td>\n",
       "      <td>0.206044</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.630429</td>\n",
       "      <td>7.615695e+06</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>8.739406</td>\n",
       "      <td>0.728284</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>7886.965607</td>\n",
       "      <td>3.994426</td>\n",
       "      <td>0.234775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495553</td>\n",
       "      <td>0.248508</td>\n",
       "      <td>0.436739</td>\n",
       "      <td>0.405019</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.074023</td>\n",
       "      <td>0.178796</td>\n",
       "      <td>0.052414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.048580e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.523576e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>4810.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>8.388327e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>48313.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label          f1            f2          f3          f4          f5  \\\n",
       "count  364.0  364.000000  3.640000e+02  364.000000  364.000000  364.000000   \n",
       "mean     1.0    3.950549  3.225865e+06    0.074176    6.013736    0.501145   \n",
       "std      0.0    7.630429  7.615695e+06    0.577344    8.739406    0.728284   \n",
       "min      1.0    0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "25%      1.0    0.000000  0.000000e+00    0.000000    1.000000    0.083333   \n",
       "50%      1.0    2.000000  7.048580e+05    0.000000    3.000000    0.250000   \n",
       "75%      1.0    4.250000  3.523576e+06    0.000000    7.000000    0.583333   \n",
       "max      1.0   69.000000  8.388327e+07   10.000000   52.000000    4.333333   \n",
       "\n",
       "               f6            f7          f8          f9     ...       f493  \\\n",
       "count  364.000000    364.000000  364.000000  364.000000     ...      364.0   \n",
       "mean     0.071592   3900.063564    0.978022    0.052198     ...        0.0   \n",
       "std      0.104041   7886.965607    3.994426    0.234775     ...        0.0   \n",
       "min      0.000000      0.000000    0.000000    0.000000     ...        0.0   \n",
       "25%      0.011905      0.000000    0.000000    0.000000     ...        0.0   \n",
       "50%      0.035714      0.000000    0.000000    0.000000     ...        0.0   \n",
       "75%      0.083333   4810.000000    0.000000    0.000000     ...        0.0   \n",
       "max      0.619048  48313.000000   39.000000    2.000000     ...        0.0   \n",
       "\n",
       "        f494        f495        f496        f497        f498        f499  \\\n",
       "count  364.0  364.000000  364.000000  364.000000  364.000000  364.000000   \n",
       "mean     0.0    0.428571    0.065934    0.255495    0.206044    0.002747   \n",
       "std      0.0    0.495553    0.248508    0.436739    0.405019    0.052414   \n",
       "min      0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.0    1.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "max      0.0    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             f500        f501        f502  \n",
       "count  364.000000  364.000000  364.000000  \n",
       "mean     0.005495    0.032967    0.002747  \n",
       "std      0.074023    0.178796    0.052414  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 503 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe of rows with label as '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6965.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  f1  f2  f3  f4   f5   f6      f7  f8  f9  ...   f493  f494  f495  \\\n",
       "0      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "1      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "2      0   0   0   0   0  0.0  0.0  6965.0   6   0  ...      0     0     0   \n",
       "3      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "4      0   0   0   0   0  0.0  0.0     0.0   0   0  ...      0     0     0   \n",
       "\n",
       "   f496  f497  f498  f499  f500  f501  f502  \n",
       "0     0     0     1     0     0     0     0  \n",
       "1     0     1     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0     0  \n",
       "3     0     1     0     0     0     0     0  \n",
       "4     0     0     0     0     0     1     0  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1=\"\"\"\n",
    "SELECT\n",
    "* FROM Lucid_0305.table1 where label=0 limit 1000\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df1 = bq.Query(query1).execute().result().to_dataframe()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concating the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1.364000e+03</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.266862</td>\n",
       "      <td>1.318182</td>\n",
       "      <td>1.000528e+06</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>2.052053</td>\n",
       "      <td>0.171004</td>\n",
       "      <td>0.024429</td>\n",
       "      <td>1657.612271</td>\n",
       "      <td>0.530059</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116569</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.230938</td>\n",
       "      <td>0.293255</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.157625</td>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.442482</td>\n",
       "      <td>5.068417</td>\n",
       "      <td>4.307993e+06</td>\n",
       "      <td>0.302088</td>\n",
       "      <td>5.871284</td>\n",
       "      <td>0.489274</td>\n",
       "      <td>0.069896</td>\n",
       "      <td>5451.689753</td>\n",
       "      <td>3.034138</td>\n",
       "      <td>0.139546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321024</td>\n",
       "      <td>0.139345</td>\n",
       "      <td>0.379667</td>\n",
       "      <td>0.421588</td>\n",
       "      <td>0.455421</td>\n",
       "      <td>0.076387</td>\n",
       "      <td>0.364522</td>\n",
       "      <td>0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>8.388327e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>48313.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label           f1            f2           f3           f4  \\\n",
       "count  1364.000000  1364.000000  1.364000e+03  1364.000000  1364.000000   \n",
       "mean      0.266862     1.318182  1.000528e+06     0.021261     2.052053   \n",
       "std       0.442482     5.068417  4.307993e+06     0.302088     5.871284   \n",
       "min       0.000000     0.000000  0.000000e+00     0.000000     0.000000   \n",
       "25%       0.000000     0.000000  0.000000e+00     0.000000     0.000000   \n",
       "50%       0.000000     0.000000  0.000000e+00     0.000000     0.000000   \n",
       "75%       1.000000     0.000000  0.000000e+00     0.000000     1.000000   \n",
       "max       1.000000    89.000000  8.388327e+07    10.000000    53.000000   \n",
       "\n",
       "                f5           f6            f7           f8           f9  \\\n",
       "count  1364.000000  1364.000000   1364.000000  1364.000000  1364.000000   \n",
       "mean      0.171004     0.024429   1657.612271     0.530059     0.018328   \n",
       "std       0.489274     0.069896   5451.689753     3.034138     0.139546   \n",
       "min       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "75%       0.083333     0.011905      0.000000     0.000000     0.000000   \n",
       "max       4.416667     0.630952  48313.000000    39.000000     2.000000   \n",
       "\n",
       "          ...         f493    f494         f495         f496         f497  \\\n",
       "count     ...       1364.0  1364.0  1364.000000  1364.000000  1364.000000   \n",
       "mean      ...          0.0     0.0     0.116569     0.019795     0.174487   \n",
       "std       ...          0.0     0.0     0.321024     0.139345     0.379667   \n",
       "min       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.0     0.0     0.000000     0.000000     0.000000   \n",
       "max       ...          0.0     0.0     1.000000     1.000000     1.000000   \n",
       "\n",
       "              f498         f499         f500         f501         f502  \n",
       "count  1364.000000  1364.000000  1364.000000  1364.000000  1364.000000  \n",
       "mean      0.230938     0.293255     0.005865     0.157625     0.001466  \n",
       "std       0.421588     0.455421     0.076387     0.364522     0.038278  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 503 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames=[df,df1]\n",
    "data=pd.concat(frames)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1     364\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (954, 502), shape of test (410, 502)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.iloc[:,1:]\n",
    "Y = data.loc[:,'label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "#Splitting train and test datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print('Shape of train {}, shape of test {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Min Max Scaling to scale the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking results of 2 scalars\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#MinMax\n",
    "MinMax = MinMaxScaler(feature_range= (0,1))\n",
    "X_train = MinMax.fit_transform(X_train)\n",
    "X_test = MinMax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2']}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lreg_clf = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty':['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(lreg_clf , param_grid, cv = 5 , return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475890985324947"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=None, columns=['model','train_Rsquare','test_Rsquare','train_MSE','test_MSE','f1_score_train','f1_score_test','train_r2_score','test_r2_score','train_precision_score','test_precision_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_r2_score</th>\n",
       "      <th>test_r2_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.041929</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.785913</td>\n",
       "      <td>0.687586</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_Rsquare  test_Rsquare  train_MSE  test_MSE  \\\n",
       "0  Logistic Regression       0.958071      0.939024   0.041929  0.060976   \n",
       "\n",
       "   f1_score_train  f1_score_test  train_r2_score  test_r2_score  \\\n",
       "0        0.915966       0.876847        0.785913       0.687586   \n",
       "\n",
       "   train_precision_score  test_precision_score  \n",
       "0               0.986425              0.946809  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_clf = LogisticRegression(penalty = 'l2')\n",
    "lreg_clf.fit(X_train,y_train)\n",
    "y_lreg_clf = lreg_clf.predict(X_test)\n",
    "train_Rsquare = lreg_clf.score(X_train, y_train)\n",
    "test_Rsquare = lreg_clf.score(X_test, y_test)\n",
    "train_MSE = mean_squared_error(y_train, lreg_clf.predict(X_train))\n",
    "test_MSE = mean_squared_error(y_test, lreg_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, lreg_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, lreg_clf.predict(X_test))\n",
    "train_r2_score=r2_score(y_train,lreg_clf.predict(X_train))\n",
    "test_r2_score=r2_score(y_test,lreg_clf.predict(X_test))\n",
    "train_precision_score=precision_score(y_train,lreg_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,lreg_clf.predict(X_test))\n",
    "results = results.append(pd.Series({'model':'Logistic Regression','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE,\n",
    "                                    'f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_r2_score':train_r2_score,'test_r2_score':test_r2_score,\n",
    "                                    'train_precision_score':train_precision_score,'test_precision_score':test_precision_score}),ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8549019607843137"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train,lreg_clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165137614678899"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,lreg_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253050576453757"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, lreg_clf.predict(X_train),pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I just wanted to see different metrics that we can consider to evaluate the model. However as it is a classification problem, the best metric would be f1_score and Precision and Recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the exact problem was known it would have been much easier to consider either of the 2 best metric. As f1 score takes the average of the precision and recall which can be pretty bad in some situations hence we will take the harmonic mean i.e. f_beta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_beta_score=precision_recall_fscore_support(y_train,lreg_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(index=None, columns=['model','f1_score_train','f1_score_test','train_precision_score','test_precision_score','f_beta_score_train','f_beta_score_test','train_recall_score','test_recall_score'])\n",
    "train_recall_score=recall_score(y_train,lreg_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,lreg_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,lreg_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,lreg_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Logistic Regression','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 4, 5, 6, 7, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[3,4, 5,6, 7,8]}\n",
    "grid_search = GridSearchCV(knn_clf , param_grid, cv = 5 , return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962264150943396"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "y_knn_clf = knn_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,knn_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,knn_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, knn_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, knn_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,knn_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,knn_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,knn_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,knn_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'KNN Classifier','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter': [1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter':[1000,10000] }\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=0,kernel='linear'), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'max_iter': 1000}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.940251572327044"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_clf = SVC(C=0.5, max_iter=1000,kernel='linear',random_state=0)\n",
    "lsvc_clf.fit(X_train,y_train)\n",
    "y_lsvc_clf = lsvc_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,lsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,lsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, lsvc_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, lsvc_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,lsvc_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,lsvc_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,lsvc_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,lsvc_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Linear','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [5, 6, 7, 8, 10, 12, 15, 20, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=10)\n",
    "param_grid = {'max_depth': [5,6,7, 8,10,12,15, 20, 50, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv = 5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580712788259959"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "3        Decision Tree        0.980080       0.913462               0.995951   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "3              0.959596            0.989464           0.955401   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  \n",
       "3            0.964706           0.871560  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth = 8)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "y_dt_clf = dt_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,dt_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,dt_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, dt_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, dt_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,dt_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,dt_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,dt_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,dt_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f34f7f81b50>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f34f7aee990>, 'bootstrap': [True, False], 'max_depth': [3, 5, 6, 8], 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f34f7aeea10>},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#Tuning ridge on new dataset\n",
    "param_grid = {\"max_depth\": [3, 5, 6,8],\n",
    "              \"max_features\": sp_randint(1, 40),\n",
    "              \"min_samples_split\": sp_randint(2, 30),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"bootstrap\": [True, False]}\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
    "                                   n_iter=20, random_state=0,n_jobs=-1, return_train_score=True)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 6,\n",
       " 'max_features': 32,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287211740041929"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "3        Decision Tree        0.980080       0.913462               0.995951   \n",
       "4        Random Forest        0.912065       0.841121               0.952991   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "3              0.959596            0.989464           0.955401   \n",
       "4              0.857143            0.954292           0.916572   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  \n",
       "3            0.964706           0.871560  \n",
       "4            0.874510           0.825688  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(bootstrap=True,max_depth=6,max_features=32,min_samples_leaf=2,min_samples_split=3)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "y_rf_clf = rf_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,rf_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rf_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, rf_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, rf_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,rf_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,rf_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,rf_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,rf_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Random Forest','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. SVC-Kernalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter': [1000, 10000], 'gamma': [0.001, 0.01, 0.1, 0.5, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter':[1000,10000], 'gamma':[0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=0,kernel='rbf'), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1, 'max_iter': 1000}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9412997903563941"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1_score_train  f1_score_test  train_precision_score  \\\n",
       "0  Logistic Regression        0.915966       0.876847               0.986425   \n",
       "1       KNN Classifier        0.877944       0.755556               0.966981   \n",
       "2           SCV-Linear        0.905660       0.891089               0.972973   \n",
       "3        Decision Tree        0.980080       0.913462               0.995951   \n",
       "4        Random Forest        0.912065       0.841121               0.952991   \n",
       "5       SCV-Kernalized        0.965517       0.904762               1.000000   \n",
       "\n",
       "   test_precision_score  f_beta_score_train  f_beta_score_test  \\\n",
       "0              0.946809            0.957072           0.937513   \n",
       "1              0.957746            0.938392           0.884541   \n",
       "2              0.967742            0.951742           0.944911   \n",
       "3              0.959596            0.989464           0.955401   \n",
       "4              0.857143            0.954292           0.916572   \n",
       "5              0.940594            0.981980           0.950610   \n",
       "\n",
       "   train_recall_score  test_recall_score  \n",
       "0            0.854902           0.816514  \n",
       "1            0.803922           0.623853  \n",
       "2            0.847059           0.825688  \n",
       "3            0.964706           0.871560  \n",
       "4            0.874510           0.825688  \n",
       "5            0.933333           0.871560  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbfsvc_clf = SVC(C=10,gamma=0.1, max_iter=1000,kernel='rbf',random_state=0,probability=True)\n",
    "rbfsvc_clf.fit(X_train,y_train)\n",
    "y_rbfsvc_clf = rbfsvc_clf.predict(X_test)\n",
    "train_precision_score=precision_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, rbfsvc_clf.predict(X_train))\n",
    "f1_score_test=f1_score(y_test, rbfsvc_clf.predict(X_test))\n",
    "train_recall_score=recall_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,rbfsvc_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,rbfsvc_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Kernalized','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'Train and Test f1_score')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f351baeced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['model','f_beta_score_train','f_beta_score_test']\n",
    "results[cols].set_index('model').plot(kind = 'bar', figsize=(15,8));\n",
    "plt.title('Train and Test f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like Decision Tree and SCV kernalized models have performed the best among all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.98\n",
      "Test score: 0.94\n"
     ]
    }
   ],
   "source": [
    "## Just trying to see how voting classifier is performing\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "hard_voting_clf = VotingClassifier(estimators=[('rbfsvc',rbfsvc_clf),('dt',dt_clf)], voting = 'hard')\n",
    "hard_voting_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(hard_voting_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(hard_voting_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Support Vector Classifier-Kernalized with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  f1_score_train  f1_score_test  \\\n",
       "0     Logistic Regression        0.915966       0.876847   \n",
       "1          KNN Classifier        0.877944       0.755556   \n",
       "2              SCV-Linear        0.905660       0.891089   \n",
       "3           Decision Tree        0.980080       0.913462   \n",
       "4           Random Forest        0.912065       0.841121   \n",
       "5          SCV-Kernalized        0.965517       0.904762   \n",
       "6  SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.959596            0.989464   \n",
       "4               0.952991              0.857143            0.954292   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.979832   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.955401            0.964706           0.871560  \n",
       "4           0.916572            0.874510           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.950610            0.925490           0.871560  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(rbfsvc_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "train_precision_score=precision_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Kernalized-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  f1_score_train  f1_score_test  \\\n",
       "0     Logistic Regression        0.915966       0.876847   \n",
       "1          KNN Classifier        0.877944       0.755556   \n",
       "2              SCV-Linear        0.905660       0.891089   \n",
       "3           Decision Tree        0.980080       0.913462   \n",
       "4           Random Forest        0.912065       0.841121   \n",
       "5          SCV-Kernalized        0.965517       0.904762   \n",
       "6  SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "7   Logistic-with-Bagging        0.958071       0.939024   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.959596            0.989464   \n",
       "4               0.952991              0.857143            0.954292   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.979832   \n",
       "7               0.986425              0.946809            0.957072   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.955401            0.964706           0.871560  \n",
       "4           0.916572            0.874510           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.950610            0.925490           0.871560  \n",
       "7           0.937513            0.854902           0.816514  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(lreg_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "train_precision_score=precision_score(y_train,bagging_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,bagging_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Logistic-with-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.988388</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  f1_score_train  f1_score_test  \\\n",
       "0         Logistic Regression        0.915966       0.876847   \n",
       "1              KNN Classifier        0.877944       0.755556   \n",
       "2                  SCV-Linear        0.905660       0.891089   \n",
       "3               Decision Tree        0.980080       0.913462   \n",
       "4               Random Forest        0.912065       0.841121   \n",
       "5              SCV-Kernalized        0.965517       0.904762   \n",
       "6      SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "7       Logistic-with-Bagging        0.958071       0.939024   \n",
       "8  Decision Tree-with-Bagging        0.988470       0.965854   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.959596            0.989464   \n",
       "4               0.952991              0.857143            0.954292   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.979832   \n",
       "7               0.986425              0.946809            0.957072   \n",
       "8               1.000000              0.952381            0.988388   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.955401            0.964706           0.871560  \n",
       "4           0.916572            0.874510           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.950610            0.925490           0.871560  \n",
       "7           0.937513            0.854902           0.816514  \n",
       "8           0.965647            0.956863           0.917431  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(dt_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "train_precision_score=precision_score(y_train,bagging_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,bagging_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree-with-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. AdaBoost Classifier for Support Vector Classifier-Kernalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.988388</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  f1_score_train  f1_score_test  \\\n",
       "0         Logistic Regression        0.915966       0.876847   \n",
       "1              KNN Classifier        0.877944       0.755556   \n",
       "2                  SCV-Linear        0.905660       0.891089   \n",
       "3               Decision Tree        0.980080       0.913462   \n",
       "4               Random Forest        0.912065       0.841121   \n",
       "5              SCV-Kernalized        0.965517       0.904762   \n",
       "6      SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "7       Logistic-with-Bagging        0.958071       0.939024   \n",
       "8  Decision Tree-with-Bagging        0.988470       0.965854   \n",
       "9     SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0               0.986425              0.946809            0.957072   \n",
       "1               0.966981              0.957746            0.938392   \n",
       "2               0.972973              0.967742            0.951742   \n",
       "3               0.995951              0.959596            0.989464   \n",
       "4               0.952991              0.857143            0.954292   \n",
       "5               1.000000              0.940594            0.981980   \n",
       "6               1.000000              0.940594            0.979832   \n",
       "7               0.986425              0.946809            0.957072   \n",
       "8               1.000000              0.952381            0.988388   \n",
       "9               0.974468              0.950000            0.966009   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.937513            0.854902           0.816514  \n",
       "1           0.884541            0.803922           0.623853  \n",
       "2           0.944911            0.847059           0.825688  \n",
       "3           0.955401            0.964706           0.871560  \n",
       "4           0.916572            0.874510           0.825688  \n",
       "5           0.950610            0.933333           0.871560  \n",
       "6           0.950610            0.925490           0.871560  \n",
       "7           0.937513            0.854902           0.816514  \n",
       "8           0.965647            0.956863           0.917431  \n",
       "9           0.953002            0.898039           0.871560  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_clf = GridSearchCV(AdaBoostClassifier(base_estimator = rbfsvc_clf,random_state = 0), param_grid, cv=5,return_train_score=True)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "train_precision_score=precision_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,adaboost_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, adaboost_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, adaboost_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,adaboost_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,adaboost_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,adaboost_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'SCV-Kernalized-Boosting','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AdaBoost Classifier for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.988388</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree-AdaBoosting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  f1_score_train  f1_score_test  \\\n",
       "0          Logistic Regression        0.915966       0.876847   \n",
       "1               KNN Classifier        0.877944       0.755556   \n",
       "2                   SCV-Linear        0.905660       0.891089   \n",
       "3                Decision Tree        0.980080       0.913462   \n",
       "4                Random Forest        0.912065       0.841121   \n",
       "5               SCV-Kernalized        0.965517       0.904762   \n",
       "6       SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "7        Logistic-with-Bagging        0.958071       0.939024   \n",
       "8   Decision Tree-with-Bagging        0.988470       0.965854   \n",
       "9      SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "10   Decision Tree-AdaBoosting        1.000000       0.956098   \n",
       "\n",
       "    train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                0.986425              0.946809            0.957072   \n",
       "1                0.966981              0.957746            0.938392   \n",
       "2                0.972973              0.967742            0.951742   \n",
       "3                0.995951              0.959596            0.989464   \n",
       "4                0.952991              0.857143            0.954292   \n",
       "5                1.000000              0.940594            0.981980   \n",
       "6                1.000000              0.940594            0.979832   \n",
       "7                0.986425              0.946809            0.957072   \n",
       "8                1.000000              0.952381            0.988388   \n",
       "9                0.974468              0.950000            0.966009   \n",
       "10               1.000000              0.933333            1.000000   \n",
       "\n",
       "    f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0            0.937513            0.854902           0.816514  \n",
       "1            0.884541            0.803922           0.623853  \n",
       "2            0.944911            0.847059           0.825688  \n",
       "3            0.955401            0.964706           0.871560  \n",
       "4            0.916572            0.874510           0.825688  \n",
       "5            0.950610            0.933333           0.871560  \n",
       "6            0.950610            0.925490           0.871560  \n",
       "7            0.937513            0.854902           0.816514  \n",
       "8            0.965647            0.956863           0.917431  \n",
       "9            0.953002            0.898039           0.871560  \n",
       "10           0.955832            1.000000           0.899083  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_clf = GridSearchCV(AdaBoostClassifier(base_estimator = dt_clf,random_state = 0), param_grid, cv=5,return_train_score=True)\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "train_precision_score=precision_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,adaboost_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, adaboost_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, adaboost_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,adaboost_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,adaboost_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,adaboost_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,adaboost_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree-AdaBoosting','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient Boosting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for GradientBoost {'max_features': 'auto', 'learning_rate': 0.1, 'max_depth': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.988388</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree-AdaBoosting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  f1_score_train  f1_score_test  \\\n",
       "0            Logistic Regression        0.915966       0.876847   \n",
       "1                 KNN Classifier        0.877944       0.755556   \n",
       "2                     SCV-Linear        0.905660       0.891089   \n",
       "3                  Decision Tree        0.980080       0.913462   \n",
       "4                  Random Forest        0.912065       0.841121   \n",
       "5                 SCV-Kernalized        0.965517       0.904762   \n",
       "6         SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "7          Logistic-with-Bagging        0.958071       0.939024   \n",
       "8     Decision Tree-with-Bagging        0.988470       0.965854   \n",
       "9        SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "10     Decision Tree-AdaBoosting        1.000000       0.956098   \n",
       "11  Gradient Boosting Classifier        1.000000       0.958537   \n",
       "\n",
       "    train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                0.986425              0.946809            0.957072   \n",
       "1                0.966981              0.957746            0.938392   \n",
       "2                0.972973              0.967742            0.951742   \n",
       "3                0.995951              0.959596            0.989464   \n",
       "4                0.952991              0.857143            0.954292   \n",
       "5                1.000000              0.940594            0.981980   \n",
       "6                1.000000              0.940594            0.979832   \n",
       "7                0.986425              0.946809            0.957072   \n",
       "8                1.000000              0.952381            0.988388   \n",
       "9                0.974468              0.950000            0.966009   \n",
       "10               1.000000              0.933333            1.000000   \n",
       "11               1.000000              0.933962            1.000000   \n",
       "\n",
       "    f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0            0.937513            0.854902           0.816514  \n",
       "1            0.884541            0.803922           0.623853  \n",
       "2            0.944911            0.847059           0.825688  \n",
       "3            0.955401            0.964706           0.871560  \n",
       "4            0.916572            0.874510           0.825688  \n",
       "5            0.950610            0.933333           0.871560  \n",
       "6            0.950610            0.925490           0.871560  \n",
       "7            0.937513            0.854902           0.816514  \n",
       "8            0.965647            0.956863           0.917431  \n",
       "9            0.953002            0.898039           0.871560  \n",
       "10           0.955832            1.000000           0.899083  \n",
       "11           0.958350            1.000000           0.908257  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=10, n_estimators= 500)\n",
    "\n",
    "param_grid = {'max_features':['auto', 'log2'], 'learning_rate' : [0.01,0.1], 'max_depth':[5,10,15,30,50]}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best parameters for {} {}'.format('GradientBoost', grid_search.best_params_))\n",
    "\n",
    "train_precision_score=precision_score(y_train,grid_search.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,grid_search.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, grid_search.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, grid_search.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,grid_search.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,grid_search.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,grid_search.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,grid_search.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Gradient Boosting Classifier','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'Train and Test f1_score')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34f7fa0b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['model','f_beta_score_train','f_beta_score_test']\n",
    "results[cols].set_index('model').plot(kind = 'bar', figsize=(15,8));\n",
    "plt.title('Train and Test f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I just graphically presented how each and every model is performing. It seems like Decision tree and Decision tree with adaboosting is performing better then other models, along with this I just wanted to see if SVC-kernalized with boosting will perform better on bigger dataset or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets work on bigger dataset (500k) and predict using the models we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f493</th>\n",
       "      <th>f494</th>\n",
       "      <th>f495</th>\n",
       "      <th>f496</th>\n",
       "      <th>f497</th>\n",
       "      <th>f498</th>\n",
       "      <th>f499</th>\n",
       "      <th>f500</th>\n",
       "      <th>f501</th>\n",
       "      <th>f502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  f1  f2  f3  f4   f5   f6   f7  f8  f9  ...   f493  f494  f495  f496  \\\n",
       "0      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "1      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "2      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "3      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "4      0   0   0   0   0  0.0  0.0  0.0   0   0  ...      0     0     0     0   \n",
       "\n",
       "   f497  f498  f499  f500  f501  f502  \n",
       "0     0     0     0     0     1     0  \n",
       "1     0     0     0     0     1     0  \n",
       "2     0     0     0     0     1     0  \n",
       "3     0     0     0     0     1     0  \n",
       "4     0     0     0     0     1     0  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1=\"\"\"\n",
    "SELECT\n",
    "* FROM Lucid_0305.table1 where label=0 limit 500000\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df2 = bq.Query(query1).execute().result().to_dataframe()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the data before feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data.iloc[:,1:] = scaler.fit_transform(data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Random Forest Classifier to extract the most important 50 variables which are best in explaining the variance in the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=8, min_samples_leaf=4, max_features=0.5, random_state=2018)\n",
    "rf.fit(data.drop(['label'],axis=1), data.label)\n",
    "features = data.drop(['label'],axis=1).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the top 50 important variables\n",
    "\n",
    "#### note: Graphs are not getting plotted in this. I used my personal computer and pasted the result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "x, y = (list(x) for x in zip(*sorted(zip(rf.feature_importances_, features), \n",
    "                                                            reverse = False)))\n",
    "trace2 = go.Bar(\n",
    "    x=x ,\n",
    "    y=y,\n",
    "    marker=dict(\n",
    "        color=x,\n",
    "        colorscale = 'Viridis',\n",
    "        reversescale = True\n",
    "    ),\n",
    "    name='Random Forest Feature importance',\n",
    "    orientation='h',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Barplot of Feature importances',\n",
    "     width = 900, height = 2000,\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "#         domain=[0, 0.85],\n",
    "    ),\n",
    "    margin=dict(\n",
    "    l=300,\n",
    "),\n",
    ")\n",
    "fig1 = go.Figure(data=[trace2])\n",
    "fig1['layout'].update(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///content/datalab/notebooks/plots.html'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.plot(fig1, filename='plots')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 50 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50=np.array(sorted(zip(rf.feature_importances_, features), reverse = True))[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_features=top_50[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forming a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_FE=data[top_50_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f23</th>\n",
       "      <th>f4</th>\n",
       "      <th>f2</th>\n",
       "      <th>f6</th>\n",
       "      <th>f495</th>\n",
       "      <th>f499</th>\n",
       "      <th>f39</th>\n",
       "      <th>f1</th>\n",
       "      <th>f5</th>\n",
       "      <th>f100</th>\n",
       "      <th>...</th>\n",
       "      <th>f489</th>\n",
       "      <th>f473</th>\n",
       "      <th>f13</th>\n",
       "      <th>f140</th>\n",
       "      <th>f22</th>\n",
       "      <th>f94</th>\n",
       "      <th>f78</th>\n",
       "      <th>f122</th>\n",
       "      <th>f87</th>\n",
       "      <th>f101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.051759</td>\n",
       "      <td>0.038718</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>0.038718</td>\n",
       "      <td>0.116569</td>\n",
       "      <td>0.293255</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>0.038718</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035191</td>\n",
       "      <td>0.068915</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>0.037390</td>\n",
       "      <td>0.037023</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.231672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.219132</td>\n",
       "      <td>0.110779</td>\n",
       "      <td>0.051357</td>\n",
       "      <td>0.110779</td>\n",
       "      <td>0.321024</td>\n",
       "      <td>0.455421</td>\n",
       "      <td>0.055792</td>\n",
       "      <td>0.056949</td>\n",
       "      <td>0.110779</td>\n",
       "      <td>0.083707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184329</td>\n",
       "      <td>0.253402</td>\n",
       "      <td>0.089855</td>\n",
       "      <td>0.189785</td>\n",
       "      <td>0.148062</td>\n",
       "      <td>0.048117</td>\n",
       "      <td>0.079821</td>\n",
       "      <td>0.093417</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.422055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               f23           f4           f2           f6         f495  \\\n",
       "count  1364.000000  1364.000000  1364.000000  1364.000000  1364.000000   \n",
       "mean      0.051759     0.038718     0.011928     0.038718     0.116569   \n",
       "std       0.219132     0.110779     0.051357     0.110779     0.321024   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000004     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000048     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000386     0.018868     0.000000     0.018868     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              f499          f39           f1           f5         f100  \\\n",
       "count  1364.000000  1364.000000  1364.000000  1364.000000  1364.000000   \n",
       "mean      0.293255     0.012577     0.014811     0.038718     0.020803   \n",
       "std       0.455421     0.055792     0.056949     0.110779     0.083707   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.003333     0.000000     0.018868     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...              f489         f473          f13         f140  \\\n",
       "count     ...       1364.000000  1364.000000  1364.000000  1364.000000   \n",
       "mean      ...          0.035191     0.068915     0.015762     0.037390   \n",
       "std       ...          0.184329     0.253402     0.089855     0.189785   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               f22          f94          f78         f122          f87  \\\n",
       "count  1364.000000  1364.000000  1364.000000  1364.000000  1364.000000   \n",
       "mean      0.037023     0.008264     0.019795     0.008798     0.005773   \n",
       "std       0.148062     0.048117     0.079821     0.093417     0.050910   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              f101  \n",
       "count  1364.000000  \n",
       "mean      0.231672  \n",
       "std       0.422055  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FE.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing again the splitting on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (954, 50), shape of test (410, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_FE\n",
    "Y = data.loc[:,'label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "#Splitting train and test datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print('Shape of train {}, shape of test {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing decision tree with bagging algorithm in order to check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.877944</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.938392</td>\n",
       "      <td>0.884541</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCV-Linear</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.951742</td>\n",
       "      <td>0.944911</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>0.955401</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912065</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>0.916572</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCV-Kernalized</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.981980</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCV-Kernalized-Bagging</td>\n",
       "      <td>0.980084</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic-with-Bagging</td>\n",
       "      <td>0.958071</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.937513</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.988388</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SCV-Kernalized-Boosting</td>\n",
       "      <td>0.966457</td>\n",
       "      <td>0.953659</td>\n",
       "      <td>0.974468</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.953002</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree-AdaBoosting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree-with-Bagging_after_FE</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.987340</td>\n",
       "      <td>0.958475</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.917431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model  f1_score_train  f1_score_test  \\\n",
       "0                   Logistic Regression        0.915966       0.876847   \n",
       "1                        KNN Classifier        0.877944       0.755556   \n",
       "2                            SCV-Linear        0.905660       0.891089   \n",
       "3                         Decision Tree        0.980080       0.913462   \n",
       "4                         Random Forest        0.912065       0.841121   \n",
       "5                        SCV-Kernalized        0.965517       0.904762   \n",
       "6                SCV-Kernalized-Bagging        0.980084       0.951220   \n",
       "7                 Logistic-with-Bagging        0.958071       0.939024   \n",
       "8            Decision Tree-with-Bagging        0.988470       0.965854   \n",
       "9               SCV-Kernalized-Boosting        0.966457       0.953659   \n",
       "10            Decision Tree-AdaBoosting        1.000000       0.956098   \n",
       "11         Gradient Boosting Classifier        1.000000       0.958537   \n",
       "12  Decision Tree-with-Bagging_after_FE        0.987421       0.958537   \n",
       "\n",
       "    train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                0.986425              0.946809            0.957072   \n",
       "1                0.966981              0.957746            0.938392   \n",
       "2                0.972973              0.967742            0.951742   \n",
       "3                0.995951              0.959596            0.989464   \n",
       "4                0.952991              0.857143            0.954292   \n",
       "5                1.000000              0.940594            0.981980   \n",
       "6                1.000000              0.940594            0.979832   \n",
       "7                0.986425              0.946809            0.957072   \n",
       "8                1.000000              0.952381            0.988388   \n",
       "9                0.974468              0.950000            0.966009   \n",
       "10               1.000000              0.933333            1.000000   \n",
       "11               1.000000              0.933962            1.000000   \n",
       "12               0.995918              0.925926            0.987340   \n",
       "\n",
       "    f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0            0.937513            0.854902           0.816514  \n",
       "1            0.884541            0.803922           0.623853  \n",
       "2            0.944911            0.847059           0.825688  \n",
       "3            0.955401            0.964706           0.871560  \n",
       "4            0.916572            0.874510           0.825688  \n",
       "5            0.950610            0.933333           0.871560  \n",
       "6            0.950610            0.925490           0.871560  \n",
       "7            0.937513            0.854902           0.816514  \n",
       "8            0.965647            0.956863           0.917431  \n",
       "9            0.953002            0.898039           0.871560  \n",
       "10           0.955832            1.000000           0.899083  \n",
       "11           0.958350            1.000000           0.908257  \n",
       "12           0.958475            0.956863           0.917431  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(dt_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "train_precision_score=precision_score(y_train,bagging_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,bagging_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results = results.append(pd.Series({'model':'Decision Tree-with-Bagging_after_FE','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing selected algorithms on the larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[top_50_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['label']=df2['label']=0\n",
    "df2.label.replace(0.0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[top_50_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f23</th>\n",
       "      <th>f4</th>\n",
       "      <th>f2</th>\n",
       "      <th>f6</th>\n",
       "      <th>f495</th>\n",
       "      <th>f499</th>\n",
       "      <th>f39</th>\n",
       "      <th>f1</th>\n",
       "      <th>f5</th>\n",
       "      <th>f100</th>\n",
       "      <th>...</th>\n",
       "      <th>f473</th>\n",
       "      <th>f13</th>\n",
       "      <th>f140</th>\n",
       "      <th>f22</th>\n",
       "      <th>f94</th>\n",
       "      <th>f78</th>\n",
       "      <th>f122</th>\n",
       "      <th>f87</th>\n",
       "      <th>f101</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.003640e+05</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>5.003640e+05</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "      <td>500364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.952281e+03</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>3.801882e+05</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>0.306765</td>\n",
       "      <td>2.525477</td>\n",
       "      <td>0.488592</td>\n",
       "      <td>0.059976</td>\n",
       "      <td>0.084934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098926</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>0.042357</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.099757</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>0.112158</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.821164e+04</td>\n",
       "      <td>2.476734</td>\n",
       "      <td>2.941264e+06</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.461294</td>\n",
       "      <td>30.535726</td>\n",
       "      <td>2.258892</td>\n",
       "      <td>0.206394</td>\n",
       "      <td>0.397274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298570</td>\n",
       "      <td>0.352376</td>\n",
       "      <td>0.201403</td>\n",
       "      <td>0.119741</td>\n",
       "      <td>0.702904</td>\n",
       "      <td>1.274229</td>\n",
       "      <td>0.064678</td>\n",
       "      <td>0.543550</td>\n",
       "      <td>0.317179</td>\n",
       "      <td>0.026962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.620000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.552000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.077094e+06</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>6.353547e+08</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18797.000000</td>\n",
       "      <td>693.000000</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>467.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f23             f4            f2             f6  \\\n",
       "count  5.003640e+05  500364.000000  5.003640e+05  500364.000000   \n",
       "mean   2.952281e+03       0.719708  3.801882e+05       0.008568   \n",
       "std    4.821164e+04       2.476734  2.941264e+06       0.029485   \n",
       "min    1.000000e+00       0.000000  0.000000e+00       0.000000   \n",
       "25%    5.000000e+01       0.000000  0.000000e+00       0.000000   \n",
       "50%    2.620000e+02       0.000000  0.000000e+00       0.000000   \n",
       "75%    1.552000e+03       0.000000  0.000000e+00       0.000000   \n",
       "max    4.077094e+06      83.000000  6.353547e+08       0.988095   \n",
       "\n",
       "                f495           f499            f39             f1  \\\n",
       "count  500364.000000  500364.000000  500364.000000  500364.000000   \n",
       "mean        0.022813       0.306765       2.525477       0.488592   \n",
       "std         0.149322       0.461294      30.535726       2.258892   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       0.000000   \n",
       "max         2.000000       2.000000   18797.000000     693.000000   \n",
       "\n",
       "                  f5           f100      ...                 f473  \\\n",
       "count  500364.000000  500364.000000      ...        500364.000000   \n",
       "mean        0.059976       0.084934      ...             0.098926   \n",
       "std         0.206394       0.397274      ...             0.298570   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%         0.000000       0.000000      ...             0.000000   \n",
       "50%         0.000000       0.000000      ...             0.000000   \n",
       "75%         0.000000       0.000000      ...             0.000000   \n",
       "max         6.916667      23.000000      ...             2.000000   \n",
       "\n",
       "                 f13           f140            f22            f94  \\\n",
       "count  500364.000000  500364.000000  500364.000000  500364.000000   \n",
       "mean        0.023071       0.042357       0.013328       0.081329   \n",
       "std         0.352376       0.201403       0.119741       0.702904   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        25.000000       1.000000       4.000000      82.000000   \n",
       "\n",
       "                 f78           f122            f87           f101  \\\n",
       "count  500364.000000  500364.000000  500364.000000  500364.000000   \n",
       "mean        0.099757       0.004201       0.027278       0.112158   \n",
       "std         1.274229       0.064678       0.543550       0.317179   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max       467.000000       1.000000     146.000000       2.000000   \n",
       "\n",
       "               label  \n",
       "count  500364.000000  \n",
       "mean        0.000727  \n",
       "std         0.026962  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames=[df,df2]\n",
    "data=pd.concat(frames)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the larger dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (350254, 50), shape of test (150110, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.loc[:,'label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "#Splitting train and test datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print('Shape of train {}, shape of test {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking results of 2 scalars\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#MinMax\n",
    "MinMax = MinMaxScaler(feature_range= (0,1))\n",
    "X_train = MinMax.fit_transform(X_train)\n",
    "X_test = MinMax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=None, columns=['model','f1_score_train','f1_score_test','train_precision_score','test_precision_score','f_beta_score_train','f_beta_score_test','train_recall_score','test_recall_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running my best models on the larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(dt_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "train_precision_score=precision_score(y_train,bagging_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,bagging_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>f_beta_score_train</th>\n",
       "      <th>f_beta_score_test</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree-with-Bagging</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.788991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  f1_score_train  f1_score_test  \\\n",
       "0  Decision Tree-with-Bagging        0.999857       0.999833   \n",
       "\n",
       "   train_precision_score  test_precision_score  f_beta_score_train  \\\n",
       "0                    1.0              0.977273            0.999849   \n",
       "\n",
       "   f_beta_score_test  train_recall_score  test_recall_score  \n",
       "0           0.999825            0.803922           0.788991  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_big = results_big.append(pd.Series({'model':'Decision Tree-with-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickling_on = open(\"Final_model.pickle\",\"wb\")\n",
    "pickle.dump(bagging_clf, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernalized SVC with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "param_grid = {\"bootstrap_features\": [True,False],\n",
    "             \"bootstrap\": [True,False]}\n",
    "bagging_clf = GridSearchCV(BaggingClassifier(rbfsvc_clf), param_grid, cv = 5, return_train_score=True)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "train_precision_score=precision_score(y_train,rbfsvc_clf.predict(X_train))\n",
    "test_precision_score=precision_score(y_test,rbfsvc_clf.predict(X_test))\n",
    "f1_score_train=f1_score(y_train, bagging_clf.predict(X_train), average = 'micro')\n",
    "f1_score_test=f1_score(y_test, bagging_clf.predict(X_test), average = 'micro')\n",
    "train_recall_score=recall_score(y_train,bagging_clf.predict(X_train))\n",
    "test_recall_score=recall_score(y_test,bagging_clf.predict(X_test))\n",
    "f_beta_score_train=precision_recall_fscore_support(y_train,bagging_clf.predict(X_train), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "f_beta_score_test=precision_recall_fscore_support(y_test,bagging_clf.predict(X_test), beta=1.0, labels=[0,1], pos_label=1, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)[2]\n",
    "results_big = results_big.append(pd.Series({'model':'SCV-Kernalized-Bagging','f1_score_train':f1_score_train,'f1_score_test':f1_score_test,'train_precision_score':train_precision_score,'train_recall_score':train_recall_score,\n",
    "                                    'test_recall_score':test_recall_score,'test_precision_score':test_precision_score,'f_beta_score_train':f_beta_score_train,'f_beta_score_test':f_beta_score_test})\n",
    "                         ,ignore_index=True )\n",
    "results_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to the models I have run, Decision tree with bagging has perform best on the bigger dataset with a f1 score (with harmonic mean) as 0.999849 for training and 0.999825 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically after presenting a model to stakeholders they will want to know which\n",
    "features were most predictive of the target column. Detail which features were\n",
    "the most predictive and your process of determining them. Note that feature\n",
    "importance does not detail the directionality of the feature, discuss ideas on what\n",
    "you could do to determine directionality of the top features.\n",
    "### ...\n",
    "#### I have used random forest in order to identify which were the most important 50 features out of 503 features which has contibuted the most in explaining the variance. Yes feature importance does not detail the directionality of the feature, in order to determine that we can either use correlation or covariance matrix which will tell us if the a particular feature has a positive relation or a negative relation with dependent variable (i.e. Label in our case)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
